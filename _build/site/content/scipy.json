{"version":2,"kind":"Article","sha256":"f4fb0d4a6b7bae2ad1f9c66cd920b7ac89d5e5c4a2464923118c1d4ed1ca9c92","slug":"scipy","location":"/03-scientific-computing-with-python/03-advanced-scientific-computing/10-scipy.md","dependencies":[],"frontmatter":{"title":"SciPy: Scientific Algorithms for Astronomy","content_includes_title":false,"authors":[{"nameParsed":{"literal":"Anna Rosen","given":"Anna","family":"Rosen"},"name":"Anna Rosen","orcid":"0000-0003-4423-0660","email":"alrosen@sdsu.edu","affiliations":["San Diego State University"],"id":"contributors-myst-generated-uid-0","corresponding":true}],"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"github":"https://github.com/astrobytes-edu/astr596-modeling-universe","subject":"Modeling the Universe","venue":{"title":"ASTR 596 - Fall 2025","url":"https://www.anna-rosen.com"},"keywords":["computational astrophysics","python","numerical methods","machine learning","monte carlo","neural networks","radiative transfer","bayesian inference","JAX"],"affiliations":[{"id":"San Diego State University","name":"San Diego State University"}],"numbering":{"title":{"offset":2}},"edit_url":"https://github.com/astrobytes-edu/astr596-modeling-universe/blob/main/03-scientific-computing-with-python/03-advanced-scientific-computing/10-scipy.md","exports":[{"format":"md","filename":"10-scipy.md","url":"/10-scipy-0b7acdb6f8f7dd000959df44f0a9c4fe.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Learning Objectives","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"snHXoVzYmt"}],"identifier":"learning-objectives","label":"Learning Objectives","html_id":"learning-objectives","implicit":true,"key":"wBsj8946No"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"By the end of this chapter, you will:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"jIXv9Hmwo1"}],"key":"tPGtzZ2Foe"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Master interpolation and integration for astronomical data","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fZ2oTJ8DCj"}],"key":"QGtIzjNqSi"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Solve ODEs for orbital dynamics and stellar evolution","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"kjP1wHc2vQ"}],"key":"cqJ5AE2rBm"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Apply optimization algorithms to fitting problems","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"QOpbs5lBQd"}],"key":"rJ5C8RNnZ0"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Use signal processing for time series and spectra","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"d6kxnN6gPi"}],"key":"o4gWBgsS1X"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Implement statistical tests for data analysis","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"LtwmVAk1kl"}],"key":"e7ctv3B3Pt"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Apply special functions in astrophysical calculations","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"WZc9eigPBT"}],"key":"a2b375oBAy"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Leverage sparse matrices for large-scale problems","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"YbhhgKjUcb"}],"key":"KuyVwurZdH"}],"key":"XOGAo465PU"},{"type":"heading","depth":2,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Introduction: SciPy’s Role in Astronomy","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"RxrDezP8d3"}],"identifier":"introduction-scipys-role-in-astronomy","label":"Introduction: SciPy’s Role in Astronomy","html_id":"introduction-scipys-role-in-astronomy","implicit":true,"key":"NXhO6U4fZ4"},{"type":"code","lang":"python","value":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import constants, special, integrate, optimize, interpolate, signal, stats\nfrom scipy.sparse import csr_matrix, linalg as sparse_linalg\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef why_scipy():\n    \"\"\"Demonstrate SciPy's value for astronomical computations.\"\"\"\n    \n    print(\"SciPy provides optimized algorithms for:\")\n    print(\"1. Physical constants\")\n    print(f\"   Speed of light: {constants.c:.0f} m/s\")\n    print(f\"   Gravitational constant: {constants.G:.4e} m³/kg/s²\")\n    print(f\"   Stefan-Boltzmann: {constants.Stefan_Boltzmann:.4e} W/m²/K⁴\")\n    \n    print(\"\\n2. Special functions\")\n    # Bessel functions for diffraction patterns\n    x = np.linspace(0, 20, 100)\n    airy_pattern = (2 * special.j1(x) / x)**2\n    print(f\"   Airy disk calculation uses Bessel function J₁\")\n    \n    print(\"\\n3. Optimized numerical algorithms\")\n    print(\"   - Integration: adaptive quadrature, ODE solvers\")\n    print(\"   - Optimization: least squares, MCMC\")\n    print(\"   - Signal processing: filters, FFT, wavelets\")\n    print(\"   - Statistics: distributions, tests, correlations\")\n\nwhy_scipy()","position":{"start":{"line":15,"column":1},"end":{"line":45,"column":1}},"key":"pPQQantdvK"},{"type":"heading","depth":2,"position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Interpolation for Astronomical Data","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"HVl40cf6vo"}],"identifier":"interpolation-for-astronomical-data","label":"Interpolation for Astronomical Data","html_id":"interpolation-for-astronomical-data","implicit":true,"key":"DHSkVGelEp"},{"type":"heading","depth":3,"position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"1D and 2D Interpolation","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"L58vEq6yZp"}],"identifier":"id-1d-and-2d-interpolation","label":"1D and 2D Interpolation","html_id":"id-1d-and-2d-interpolation","implicit":true,"key":"GZXqTLg8cU"},{"type":"code","lang":"python","value":"def interpolation_examples():\n    \"\"\"Interpolation methods for astronomical data.\"\"\"\n    \n    # 1D Spectral interpolation\n    print(\"1. Spectral Line Interpolation\")\n    \n    # Original spectrum (low resolution)\n    wave_obs = np.array([4000, 4500, 5000, 5500, 6000, 6500, 7000])\n    flux_obs = np.array([0.8, 0.85, 0.9, 0.95, 1.0, 0.92, 0.88])\n    \n    # Different interpolation methods\n    wave_high = np.linspace(4000, 7000, 1000)\n    \n    # Linear interpolation\n    interp_linear = interpolate.interp1d(wave_obs, flux_obs, kind='linear')\n    flux_linear = interp_linear(wave_high)\n    \n    # Cubic spline\n    interp_cubic = interpolate.interp1d(wave_obs, flux_obs, kind='cubic')\n    flux_cubic = interp_cubic(wave_high)\n    \n    # Akima spline (less oscillation)\n    from scipy.interpolate import Akima1DInterpolator\n    interp_akima = Akima1DInterpolator(wave_obs, flux_obs)\n    flux_akima = interp_akima(wave_high)\n    \n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    for ax, flux, title in zip(axes, \n                               [flux_linear, flux_cubic, flux_akima],\n                               ['Linear', 'Cubic', 'Akima']):\n        ax.plot(wave_high, flux, 'b-', linewidth=1, label='Interpolated')\n        ax.plot(wave_obs, flux_obs, 'ro', markersize=6, label='Observed')\n        ax.set_xlabel('Wavelength [Å]')\n        ax.set_ylabel('Flux')\n        ax.set_title(f'{title} Interpolation')\n        ax.legend()\n        ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # 2D Image interpolation\n    print(\"\\n2. PSF Interpolation Across Detector\")\n    \n    # PSF measurements at specific positions\n    x_psf = np.array([0, 512, 1024, 0, 512, 1024, 0, 512, 1024])\n    y_psf = np.array([0, 0, 0, 512, 512, 512, 1024, 1024, 1024])\n    fwhm_psf = np.array([2.1, 2.0, 2.2, 2.0, 1.9, 2.1, 2.2, 2.1, 2.3])\n    \n    # Interpolate across entire detector\n    x_grid = np.arange(0, 1025, 32)\n    y_grid = np.arange(0, 1025, 32)\n    X_grid, Y_grid = np.meshgrid(x_grid, y_grid)\n    \n    # Different 2D interpolation methods\n    from scipy.interpolate import griddata\n    \n    # Linear interpolation\n    fwhm_linear = griddata((x_psf, y_psf), fwhm_psf, \n                          (X_grid, Y_grid), method='linear')\n    \n    # Cubic interpolation\n    fwhm_cubic = griddata((x_psf, y_psf), fwhm_psf, \n                         (X_grid, Y_grid), method='cubic')\n    \n    # Radial basis function\n    from scipy.interpolate import Rbf\n    rbf = Rbf(x_psf, y_psf, fwhm_psf, function='thin_plate')\n    fwhm_rbf = rbf(X_grid, Y_grid)\n    \n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    for ax, data, title in zip(axes, \n                               [fwhm_linear, fwhm_cubic, fwhm_rbf],\n                               ['Linear', 'Cubic', 'RBF']):\n        im = ax.contourf(X_grid, Y_grid, data, levels=20, cmap='viridis')\n        ax.scatter(x_psf, y_psf, c='red', s=50, marker='x')\n        ax.set_xlabel('X [pixels]')\n        ax.set_ylabel('Y [pixels]')\n        ax.set_title(f'{title} PSF Interpolation')\n        plt.colorbar(im, ax=ax, label='FWHM [pixels]')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return wave_high, flux_cubic\n\nwavelengths, spectrum = interpolation_examples()","position":{"start":{"line":51,"column":1},"end":{"line":141,"column":1}},"key":"CnLd9faHtw"},{"type":"heading","depth":3,"position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"children":[{"type":"text","value":"Extrapolation and Edge Effects","position":{"start":{"line":143,"column":1},"end":{"line":143,"column":1}},"key":"gwdniWeovi"}],"identifier":"extrapolation-and-edge-effects","label":"Extrapolation and Edge Effects","html_id":"extrapolation-and-edge-effects","implicit":true,"key":"ViiiYQgvkO"},{"type":"code","lang":"python","value":"def extrapolation_pitfalls():\n    \"\"\"Demonstrate dangers of extrapolation.\"\"\"\n    \n    # Observed data (limited range)\n    redshift = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n    distance = np.array([450, 1400, 2200, 3100, 4000])  # Mpc\n    \n    # Try to extrapolate\n    z_range = np.linspace(0, 2, 100)\n    \n    # Different extrapolation approaches\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    # Linear extrapolation (dangerous!)\n    f_linear = interpolate.interp1d(redshift, distance, \n                                   kind='linear', fill_value='extrapolate')\n    d_linear = f_linear(z_range)\n    \n    axes[0].plot(z_range, d_linear, 'b-', label='Linear extrap')\n    axes[0].plot(redshift, distance, 'ro', markersize=8, label='Data')\n    axes[0].axvspan(1.0, 2.0, alpha=0.2, color='red', label='Danger zone')\n    axes[0].set_xlabel('Redshift')\n    axes[0].set_ylabel('Distance [Mpc]')\n    axes[0].set_title('Linear Extrapolation (BAD)')\n    axes[0].legend()\n    \n    # Polynomial fit (also dangerous!)\n    poly_coef = np.polyfit(redshift, distance, 3)\n    d_poly = np.polyval(poly_coef, z_range)\n    \n    axes[1].plot(z_range, d_poly, 'g-', label='Polynomial')\n    axes[1].plot(redshift, distance, 'ro', markersize=8, label='Data')\n    axes[1].axvspan(1.0, 2.0, alpha=0.2, color='red')\n    axes[1].set_xlabel('Redshift')\n    axes[1].set_title('Polynomial Extrapolation (WORSE)')\n    axes[1].legend()\n    \n    # Physical model (better)\n    from scipy.integrate import quad\n    \n    def luminosity_distance(z, H0=70, Om0=0.3, OL0=0.7):\n        \"\"\"Calculate luminosity distance using cosmology.\"\"\"\n        c = 3e5  # km/s\n        \n        def integrand(zp):\n            return 1 / np.sqrt(Om0*(1+zp)**3 + OL0)\n        \n        integral, _ = quad(integrand, 0, z)\n        return c/H0 * (1+z) * integral\n    \n    d_model = [luminosity_distance(z) for z in z_range]\n    \n    axes[2].plot(z_range, d_model, 'k-', label='ΛCDM model')\n    axes[2].plot(redshift, distance, 'ro', markersize=8, label='Data')\n    axes[2].set_xlabel('Redshift')\n    axes[2].set_title('Physical Model (GOOD)')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"Lesson: Use physical models, not blind extrapolation!\")\n\nextrapolation_pitfalls()","position":{"start":{"line":145,"column":1},"end":{"line":210,"column":1}},"key":"hwmJvLNkDC"},{"type":"heading","depth":2,"position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"children":[{"type":"text","value":"Integration Techniques","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"key":"m40oi2SFDC"}],"identifier":"integration-techniques","label":"Integration Techniques","html_id":"integration-techniques","implicit":true,"key":"SOlNkhOEcd"},{"type":"heading","depth":3,"position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"children":[{"type":"text","value":"Numerical Integration Methods","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"U5dvfnnRXq"}],"identifier":"numerical-integration-methods","label":"Numerical Integration Methods","html_id":"numerical-integration-methods","implicit":true,"key":"YPZeCMmAx6"},{"type":"code","lang":"python","value":"def integration_showcase():\n    \"\"\"Compare integration methods for astronomical applications.\"\"\"\n    \n    # 1. Integrate stellar spectrum to get bolometric luminosity\n    print(\"1. Bolometric Luminosity Calculation\")\n    \n    # Planck function\n    def planck(wavelength, T):\n        \"\"\"Planck function in wavelength space.\"\"\"\n        h = constants.h\n        c = constants.c\n        k = constants.k\n        \n        wavelength = wavelength * 1e-9  # Convert nm to m\n        \n        with np.errstate(over='ignore'):\n            B = (2*h*c**2/wavelength**5) / (np.exp(h*c/(wavelength*k*T)) - 1)\n        \n        return B\n    \n    # Integrate over all wavelengths\n    T_star = 5778  # Solar temperature\n    \n    # Method 1: Fixed quadrature\n    from scipy.integrate import quad\n    L_quad, error = quad(lambda lam: planck(lam, T_star), 10, 100000)\n    \n    # Method 2: Adaptive quadrature with specified tolerance\n    from scipy.integrate import quad_vec\n    wavelengths = np.logspace(1, 5, 1000)  # 10 nm to 100 μm\n    integrand = planck(wavelengths, T_star)\n    L_trapz = np.trapz(integrand, wavelengths)\n    \n    # Method 3: Romberg integration\n    from scipy.integrate import romberg\n    L_romberg = romberg(lambda lam: planck(lam, T_star), 10, 100000)\n    \n    print(f\"  Quadrature: L = {L_quad:.3e} W/m²/sr\")\n    print(f\"  Trapezoid:  L = {L_trapz:.3e} W/m²/sr\")\n    print(f\"  Romberg:    L = {L_romberg:.3e} W/m²/sr\")\n    print(f\"  Stefan-Boltzmann: σT⁴ = {constants.Stefan_Boltzmann * T_star**4:.3e} W/m²\")\n    \n    # 2. Mass enclosed in galaxy profile\n    print(\"\\n2. Galaxy Mass Profile\")\n    \n    def density_profile(r, rho0=1e7, rs=10):\n        \"\"\"NFW dark matter density profile.\"\"\"\n        x = r / rs\n        return rho0 / (x * (1 + x)**2)\n    \n    def mass_enclosed(R, rho0=1e7, rs=10):\n        \"\"\"Integrate density to get enclosed mass.\"\"\"\n        \n        def integrand(r):\n            return 4 * np.pi * r**2 * density_profile(r, rho0, rs)\n        \n        mass, _ = quad(integrand, 0, R)\n        return mass\n    \n    radii = np.logspace(0, 3, 50)  # 1 to 1000 kpc\n    masses = [mass_enclosed(R) for R in radii]\n    \n    # Analytical solution for NFW\n    def mass_nfw_analytical(R, rho0=1e7, rs=10):\n        \"\"\"Analytical NFW enclosed mass.\"\"\"\n        x = R / rs\n        return 4 * np.pi * rho0 * rs**3 * (np.log(1+x) - x/(1+x))\n    \n    masses_analytical = [mass_nfw_analytical(R) for R in radii]\n    \n    fig, ax = plt.subplots(figsize=(8, 5))\n    ax.loglog(radii, masses, 'b-', linewidth=2, label='Numerical')\n    ax.loglog(radii, masses_analytical, 'r--', linewidth=2, label='Analytical')\n    ax.set_xlabel('Radius [kpc]')\n    ax.set_ylabel('Enclosed Mass [M☉]')\n    ax.set_title('NFW Profile Mass Integration')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.show()\n\nintegration_showcase()","position":{"start":{"line":216,"column":1},"end":{"line":298,"column":1}},"key":"kxDr2DvQ2Z"},{"type":"heading","depth":3,"position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"text","value":"Multi-dimensional Integration","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"hpIULYwF2h"}],"identifier":"multi-dimensional-integration","label":"Multi-dimensional Integration","html_id":"multi-dimensional-integration","implicit":true,"key":"zT1KnBOZ65"},{"type":"code","lang":"python","value":"def multidimensional_integration():\n    \"\"\"Multi-dimensional integration for complex geometries.\"\"\"\n    \n    # Calculate volume and mass of triaxial galaxy\n    print(\"Triaxial Galaxy Mass Calculation\")\n    \n    def galaxy_density(x, y, z, a=20, b=10, c=5, rho0=1e8):\n        \"\"\"Density in triaxial galaxy.\"\"\"\n        r_ell = np.sqrt((x/a)**2 + (y/b)**2 + (z/c)**2)\n        if r_ell > 1:\n            return 0\n        return rho0 * np.exp(-r_ell)\n    \n    # Method 1: Triple integral\n    from scipy.integrate import tplquad\n    \n    mass, error = tplquad(\n        galaxy_density,\n        -5, 5,  # z limits\n        lambda z: -10, lambda z: 10,  # y limits\n        lambda z, y: -20, lambda z, y: 20  # x limits\n    )\n    \n    print(f\"  Total mass (tplquad): {mass:.3e} M☉\")\n    print(f\"  Relative error: {error/mass:.3e}\")\n    \n    # Method 2: Monte Carlo integration\n    def monte_carlo_integrate(n_samples=100000):\n        \"\"\"Monte Carlo integration for complex shapes.\"\"\"\n        # Sample in bounding box\n        x = np.random.uniform(-20, 20, n_samples)\n        y = np.random.uniform(-10, 10, n_samples)\n        z = np.random.uniform(-5, 5, n_samples)\n        \n        # Evaluate density\n        densities = np.array([galaxy_density(xi, yi, zi) \n                             for xi, yi, zi in zip(x, y, z)])\n        \n        # Volume of bounding box\n        volume = 40 * 20 * 10\n        \n        # Monte Carlo estimate\n        mass_mc = volume * np.mean(densities)\n        error_mc = volume * np.std(densities) / np.sqrt(n_samples)\n        \n        return mass_mc, error_mc\n    \n    mass_mc, error_mc = monte_carlo_integrate()\n    print(f\"  Total mass (Monte Carlo): {mass_mc:.3e} ± {error_mc:.3e} M☉\")\n\nmultidimensional_integration()","position":{"start":{"line":302,"column":1},"end":{"line":354,"column":1}},"key":"OQAyKQe208"},{"type":"heading","depth":2,"position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"children":[{"type":"text","value":"Differential Equations for Dynamics","position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"key":"ENI1sfhvZr"}],"identifier":"differential-equations-for-dynamics","label":"Differential Equations for Dynamics","html_id":"differential-equations-for-dynamics","implicit":true,"key":"Zd2xk3L0wS"},{"type":"heading","depth":3,"position":{"start":{"line":358,"column":1},"end":{"line":358,"column":1}},"children":[{"type":"text","value":"Solving ODEs: Orbital Mechanics","position":{"start":{"line":358,"column":1},"end":{"line":358,"column":1}},"key":"S6t2x1Ckh7"}],"identifier":"solving-odes-orbital-mechanics","label":"Solving ODEs: Orbital Mechanics","html_id":"solving-odes-orbital-mechanics","implicit":true,"key":"XT9kKphQvq"},{"type":"code","lang":"python","value":"def orbital_dynamics():\n    \"\"\"Solve orbital dynamics with various methods.\"\"\"\n    \n    def three_body_system(t, state, m1, m2, m3):\n        \"\"\"\n        Three-body gravitational system.\n        State = [x1, y1, z1, x2, y2, z2, x3, y3, z3,\n                vx1, vy1, vz1, vx2, vy2, vz2, vx3, vy3, vz3]\n        \"\"\"\n        G = constants.G\n        \n        # Unpack positions and velocities\n        r1 = state[0:3]\n        r2 = state[3:6]\n        r3 = state[6:9]\n        v1 = state[9:12]\n        v2 = state[12:15]\n        v3 = state[15:18]\n        \n        # Calculate distances\n        r12 = np.linalg.norm(r2 - r1)\n        r13 = np.linalg.norm(r3 - r1)\n        r23 = np.linalg.norm(r3 - r2)\n        \n        # Calculate accelerations\n        a1 = G*m2*(r2-r1)/r12**3 + G*m3*(r3-r1)/r13**3\n        a2 = G*m1*(r1-r2)/r12**3 + G*m3*(r3-r2)/r23**3\n        a3 = G*m1*(r1-r3)/r13**3 + G*m2*(r2-r3)/r23**3\n        \n        # Return derivatives\n        return np.concatenate([v1, v2, v3, a1, a2, a3])\n    \n    # Set up figure-8 solution (approximate)\n    x0 = 0.97000436\n    y0 = 0.0\n    vx0 = -0.93240737\n    vy0 = -0.86473146\n    \n    # Initial conditions (scaled units where G=1, m=1)\n    state0 = np.array([\n        x0, -y0, 0,     # Body 1 position\n        -x0, y0, 0,     # Body 2 position\n        0, 0, 0,        # Body 3 position\n        vx0/2, vy0/2, 0,  # Body 1 velocity\n        vx0/2, vy0/2, 0,  # Body 2 velocity\n        -vx0, -vy0, 0     # Body 3 velocity\n    ])\n    \n    # Solve with different methods\n    t_span = (0, 6)\n    t_eval = np.linspace(0, 6, 1000)\n    \n    # RK45 (adaptive step)\n    from scipy.integrate import solve_ivp\n    \n    sol_rk45 = solve_ivp(\n        three_body_system, t_span, state0, \n        method='RK45', t_eval=t_eval, \n        args=(1, 1, 1), rtol=1e-10\n    )\n    \n    # DOP853 (8th order, good for long integration)\n    sol_dop853 = solve_ivp(\n        three_body_system, t_span, state0,\n        method='DOP853', t_eval=t_eval,\n        args=(1, 1, 1), rtol=1e-10\n    )\n    \n    # Plot orbits\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # RK45 solution\n    for i, color in enumerate(['red', 'blue', 'green']):\n        axes[0].plot(sol_rk45.y[3*i], sol_rk45.y[3*i+1], \n                    color=color, linewidth=1, alpha=0.7,\n                    label=f'Body {i+1}')\n    axes[0].set_xlabel('X')\n    axes[0].set_ylabel('Y')\n    axes[0].set_title('Three-Body Orbits (RK45)')\n    axes[0].legend()\n    axes[0].axis('equal')\n    axes[0].grid(True, alpha=0.3)\n    \n    # Energy conservation check\n    def total_energy(state, m1, m2, m3):\n        \"\"\"Calculate total energy of system.\"\"\"\n        G = 1  # Scaled units\n        \n        r1, r2, r3 = state[0:3], state[3:6], state[6:9]\n        v1, v2, v3 = state[9:12], state[12:15], state[15:18]\n        \n        # Kinetic energy\n        KE = 0.5 * (m1*np.sum(v1**2) + m2*np.sum(v2**2) + m3*np.sum(v3**2))\n        \n        # Potential energy\n        r12 = np.linalg.norm(r2 - r1)\n        r13 = np.linalg.norm(r3 - r1)\n        r23 = np.linalg.norm(r3 - r2)\n        PE = -G * (m1*m2/r12 + m1*m3/r13 + m2*m3/r23)\n        \n        return KE + PE\n    \n    energies = [total_energy(sol_rk45.y[:, i], 1, 1, 1) \n                for i in range(len(t_eval))]\n    \n    axes[1].plot(t_eval, energies, 'k-', linewidth=1)\n    axes[1].set_xlabel('Time')\n    axes[1].set_ylabel('Total Energy')\n    axes[1].set_title('Energy Conservation')\n    axes[1].grid(True, alpha=0.3)\n    \n    drift = (energies[-1] - energies[0]) / energies[0]\n    axes[1].text(0.5, 0.95, f'Relative drift: {drift:.3e}',\n                transform=axes[1].transAxes, ha='center')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return sol_rk45\n\nsolution = orbital_dynamics()","position":{"start":{"line":360,"column":1},"end":{"line":482,"column":1}},"key":"waCcYzLfrh"},{"type":"heading","depth":2,"position":{"start":{"line":484,"column":1},"end":{"line":484,"column":1}},"children":[{"type":"text","value":"Optimization and Fitting","position":{"start":{"line":484,"column":1},"end":{"line":484,"column":1}},"key":"mWgdf3R8DH"}],"identifier":"optimization-and-fitting","label":"Optimization and Fitting","html_id":"optimization-and-fitting","implicit":true,"key":"ZnrvMshGqD"},{"type":"heading","depth":3,"position":{"start":{"line":486,"column":1},"end":{"line":486,"column":1}},"children":[{"type":"text","value":"Least Squares Fitting","position":{"start":{"line":486,"column":1},"end":{"line":486,"column":1}},"key":"qRfvcUaZc7"}],"identifier":"least-squares-fitting","label":"Least Squares Fitting","html_id":"least-squares-fitting","implicit":true,"key":"ehO7aX1ALE"},{"type":"code","lang":"python","value":"def optimization_examples():\n    \"\"\"Optimization methods for astronomical data fitting.\"\"\"\n    \n    # Generate synthetic supernova light curve\n    np.random.seed(42)\n    \n    def supernova_model(t, t0, A, tau_rise, tau_fall):\n        \"\"\"Simplified supernova light curve model.\"\"\"\n        phase = t - t0\n        flux = np.zeros_like(t)\n        \n        # Rising phase\n        mask_rise = (phase >= 0) & (phase < tau_rise)\n        flux[mask_rise] = A * (1 - np.exp(-phase[mask_rise]/tau_rise*3))\n        \n        # Falling phase\n        mask_fall = phase >= tau_rise\n        flux[mask_fall] = A * np.exp(-(phase[mask_fall]-tau_rise)/tau_fall)\n        \n        return flux\n    \n    # True parameters\n    true_params = dict(t0=50, A=100, tau_rise=15, tau_fall=30)\n    \n    # Generate data\n    t_obs = np.linspace(0, 150, 50)\n    flux_true = supernova_model(t_obs, **true_params)\n    flux_err = 5 + 0.05 * flux_true  # Heteroscedastic errors\n    flux_obs = flux_true + np.random.normal(0, flux_err)\n    \n    # 1. Simple least squares\n    from scipy.optimize import curve_fit\n    \n    popt, pcov = curve_fit(\n        supernova_model, t_obs, flux_obs,\n        p0=[45, 90, 10, 25],  # Initial guess\n        sigma=flux_err,\n        absolute_sigma=True\n    )\n    \n    perr = np.sqrt(np.diag(pcov))\n    \n    print(\"Least Squares Fit:\")\n    param_names = ['t0', 'A', 'tau_rise', 'tau_fall']\n    for name, val, err, true in zip(param_names, popt, perr, true_params.values()):\n        print(f\"  {name}: {val:.2f} ± {err:.2f} (true: {true})\")\n    \n    # 2. Robust fitting (handles outliers)\n    from scipy.optimize import least_squares\n    \n    def residuals(params, t, flux, flux_err):\n        model = supernova_model(t, *params)\n        return (flux - model) / flux_err\n    \n    # Add outliers\n    flux_outliers = flux_obs.copy()\n    flux_outliers[10] += 50  # Bad pixel\n    flux_outliers[30] -= 40  # Cosmic ray\n    \n    # Huber loss (robust to outliers)\n    result_robust = least_squares(\n        residuals, [45, 90, 10, 25],\n        args=(t_obs, flux_outliers, flux_err),\n        loss='huber'\n    )\n    \n    print(\"\\nRobust Fit (with outliers):\")\n    for name, val in zip(param_names, result_robust.x):\n        print(f\"  {name}: {val:.2f}\")\n    \n    # 3. Global optimization (for complex χ² surfaces)\n    from scipy.optimize import differential_evolution\n    \n    def chi2(params, t, flux, flux_err):\n        model = supernova_model(t, *params)\n        return np.sum(((flux - model) / flux_err)**2)\n    \n    bounds = [(40, 60), (50, 150), (5, 25), (20, 40)]\n    \n    result_global = differential_evolution(\n        chi2, bounds,\n        args=(t_obs, flux_obs, flux_err),\n        seed=42\n    )\n    \n    print(\"\\nGlobal Optimization:\")\n    for name, val in zip(param_names, result_global.x):\n        print(f\"  {name}: {val:.2f}\")\n    \n    # Plot results\n    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n    \n    t_model = np.linspace(0, 150, 500)\n    \n    # Original fit\n    axes[0, 0].errorbar(t_obs, flux_obs, yerr=flux_err, \n                       fmt='ko', markersize=4, alpha=0.5, label='Data')\n    axes[0, 0].plot(t_model, supernova_model(t_model, *popt), \n                   'b-', linewidth=2, label='Least Squares')\n    axes[0, 0].plot(t_model, supernova_model(t_model, **true_params), \n                   'r--', linewidth=2, label='True')\n    axes[0, 0].set_xlabel('Time [days]')\n    axes[0, 0].set_ylabel('Flux')\n    axes[0, 0].set_title('Standard Least Squares')\n    axes[0, 0].legend()\n    \n    # With outliers\n    axes[0, 1].errorbar(t_obs, flux_outliers, yerr=flux_err,\n                       fmt='ko', markersize=4, alpha=0.5, label='Data+outliers')\n    axes[0, 1].plot(t_model, supernova_model(t_model, *result_robust.x),\n                   'g-', linewidth=2, label='Robust fit')\n    axes[0, 1].plot(t_model, supernova_model(t_model, *popt),\n                   'b--', linewidth=2, alpha=0.5, label='Standard fit')\n    axes[0, 1].set_xlabel('Time [days]')\n    axes[0, 1].set_ylabel('Flux')\n    axes[0, 1].set_title('Robust Fitting')\n    axes[0, 1].legend()\n    \n    # Residuals\n    residuals_standard = flux_obs - supernova_model(t_obs, *popt)\n    residuals_robust = flux_outliers - supernova_model(t_obs, *result_robust.x)\n    \n    axes[1, 0].scatter(t_obs, residuals_standard/flux_err, alpha=0.5)\n    axes[1, 0].axhline(0, color='r', linestyle='--')\n    axes[1, 0].set_xlabel('Time [days]')\n    axes[1, 0].set_ylabel('Normalized Residuals')\n    axes[1, 0].set_title('Residuals (Standard)')\n    axes[1, 0].set_ylim(-5, 5)\n    \n    axes[1, 1].scatter(t_obs, residuals_robust/flux_err, alpha=0.5)\n    axes[1, 1].axhline(0, color='r', linestyle='--')\n    axes[1, 1].set_xlabel('Time [days]')\n    axes[1, 1].set_ylabel('Normalized Residuals')\n    axes[1, 1].set_title('Residuals (Robust)')\n    axes[1, 1].set_ylim(-5, 5)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return popt, pcov\n\nparams, covariance = optimization_examples()","position":{"start":{"line":488,"column":1},"end":{"line":631,"column":1}},"key":"abMJlY8pfi"},{"type":"heading","depth":2,"position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"children":[{"type":"text","value":"Signal Processing for Time Series","position":{"start":{"line":633,"column":1},"end":{"line":633,"column":1}},"key":"E6TlGnXW03"}],"identifier":"signal-processing-for-time-series","label":"Signal Processing for Time Series","html_id":"signal-processing-for-time-series","implicit":true,"key":"NPdfLINi5m"},{"type":"heading","depth":3,"position":{"start":{"line":635,"column":1},"end":{"line":635,"column":1}},"children":[{"type":"text","value":"Fourier Analysis and Filtering","position":{"start":{"line":635,"column":1},"end":{"line":635,"column":1}},"key":"SJEgetEx6i"}],"identifier":"fourier-analysis-and-filtering","label":"Fourier Analysis and Filtering","html_id":"fourier-analysis-and-filtering","implicit":true,"key":"Mnw6yxY619"},{"type":"code","lang":"python","value":"def signal_processing_astronomy():\n    \"\"\"Signal processing for astronomical time series.\"\"\"\n    \n    # Generate synthetic variable star data\n    np.random.seed(42)\n    \n    # Time sampling (uneven, realistic for ground-based)\n    n_nights = 200\n    t_obs = []\n    for night in range(n_nights):\n        # Random number of observations per night\n        n_obs = np.random.poisson(5)\n        if n_obs > 0:\n            # Observations within 6-hour window\n            t_night = night + np.random.uniform(0, 0.25, n_obs)\n            t_obs.extend(t_night)\n    \n    t_obs = np.array(sorted(t_obs))\n    \n    # Multi-periodic signal\n    P1, P2 = 2.3456, 3.7890  # Periods in days\n    A1, A2 = 0.1, 0.05  # Amplitudes\n    \n    signal = (A1 * np.sin(2*np.pi*t_obs/P1) + \n             A2 * np.sin(2*np.pi*t_obs/P2 + 1.5))\n    \n    # Add noise and trends\n    noise = np.random.normal(0, 0.02, len(t_obs))\n    trend = 0.0001 * t_obs  # Linear trend\n    flux = 1.0 + signal + noise + trend\n    \n    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n    \n    # 1. Raw data\n    axes[0, 0].scatter(t_obs, flux, s=1, alpha=0.5)\n    axes[0, 0].set_xlabel('Time [days]')\n    axes[0, 0].set_ylabel('Flux')\n    axes[0, 0].set_title('Raw Light Curve')\n    \n    # 2. Lomb-Scargle periodogram (for uneven sampling)\n    from scipy.signal import lombscargle\n    \n    frequencies = np.linspace(0.1, 2, 1000)\n    periods = 1 / frequencies\n    \n    # Normalize data\n    flux_norm = flux - np.mean(flux)\n    \n    # Compute periodogram\n    power = lombscargle(t_obs, flux_norm, 2*np.pi*frequencies)\n    \n    # Normalize power\n    power = power / power.max()\n    \n    axes[0, 1].plot(periods, power, 'k-', linewidth=1)\n    axes[0, 1].axvline(P1, color='red', linestyle='--', alpha=0.5, label=f'P1={P1:.3f}')\n    axes[0, 1].axvline(P2, color='blue', linestyle='--', alpha=0.5, label=f'P2={P2:.3f}')\n    axes[0, 1].set_xlabel('Period [days]')\n    axes[0, 1].set_ylabel('Power')\n    axes[0, 1].set_title('Lomb-Scargle Periodogram')\n    axes[0, 1].set_xlim(0, 10)\n    axes[0, 1].legend()\n    \n    # 3. Detrending\n    from scipy.signal import detrend\n    \n    # Polynomial detrending\n    poly_coef = np.polyfit(t_obs, flux, 2)\n    trend_fit = np.polyval(poly_coef, t_obs)\n    flux_detrended = flux - trend_fit + np.mean(flux)\n    \n    axes[0, 2].scatter(t_obs, flux_detrended, s=1, alpha=0.5)\n    axes[0, 2].set_xlabel('Time [days]')\n    axes[0, 2].set_ylabel('Flux')\n    axes[0, 2].set_title('Detrended Light Curve')\n    \n    # 4. Filtering\n    from scipy.signal import savgol_filter\n    \n    # Need regular sampling for filtering\n    t_regular = np.linspace(t_obs.min(), t_obs.max(), 2000)\n    flux_interp = np.interp(t_regular, t_obs, flux_detrended)\n    \n    # Savitzky-Golay filter\n    flux_smooth = savgol_filter(flux_interp, 51, 3)\n    \n    axes[1, 0].plot(t_regular, flux_interp, 'k-', alpha=0.3, linewidth=0.5, label='Interpolated')\n    axes[1, 0].plot(t_regular, flux_smooth, 'r-', linewidth=2, label='Smoothed')\n    axes[1, 0].set_xlabel('Time [days]')\n    axes[1, 0].set_ylabel('Flux')\n    axes[1, 0].set_title('Savitzky-Golay Filter')\n    axes[1, 0].set_xlim(50, 60)  # Zoom in\n    axes[1, 0].legend()\n    \n    # 5. Wavelet analysis\n    from scipy.signal import cwt, ricker\n    \n    # Continuous wavelet transform\n    widths = np.arange(1, 100)\n    cwt_matrix = cwt(flux_interp, ricker, widths)\n    \n    im = axes[1, 1].imshow(np.abs(cwt_matrix), extent=[t_regular.min(), t_regular.max(), \n                                                        widths[-1], widths[0]], \n                          cmap='viridis', aspect='auto')\n    axes[1, 1].set_xlabel('Time [days]')\n    axes[1, 1].set_ylabel('Scale')\n    axes[1, 1].set_title('Wavelet Transform')\n    plt.colorbar(im, ax=axes[1, 1])\n    \n    # 6. Phase folding\n    best_period = P1  # Use known period\n    phase = (t_obs % best_period) / best_period\n    \n    axes[1, 2].scatter(phase, flux_detrended, s=1, alpha=0.3, c='k')\n    axes[1, 2].scatter(phase + 1, flux_detrended, s=1, alpha=0.3, c='k')  # Repeat\n    \n    # Binned curve\n    phase_bins = np.linspace(0, 1, 20)\n    binned_flux = []\n    for i in range(len(phase_bins)-1):\n        mask = (phase > phase_bins[i]) & (phase < phase_bins[i+1])\n        if mask.sum() > 0:\n            binned_flux.append(np.median(flux_detrended[mask]))\n        else:\n            binned_flux.append(np.nan)\n    \n    bin_centers = (phase_bins[:-1] + phase_bins[1:]) / 2\n    axes[1, 2].plot(bin_centers, binned_flux, 'ro-', linewidth=2, markersize=5)\n    axes[1, 2].set_xlabel('Phase')\n    axes[1, 2].set_ylabel('Flux')\n    axes[1, 2].set_title(f'Phase-folded (P={best_period:.4f} days)')\n    axes[1, 2].set_xlim(0, 2)\n    \n    plt.tight_layout()\n    plt.show()\n\nsignal_processing_astronomy()","position":{"start":{"line":637,"column":1},"end":{"line":775,"column":1}},"key":"w3OJEB3bXJ"},{"type":"heading","depth":2,"position":{"start":{"line":777,"column":1},"end":{"line":777,"column":1}},"children":[{"type":"text","value":"Statistical Analysis","position":{"start":{"line":777,"column":1},"end":{"line":777,"column":1}},"key":"gO6YJpxDkA"}],"identifier":"statistical-analysis","label":"Statistical Analysis","html_id":"statistical-analysis","implicit":true,"key":"ALEB2CP8c4"},{"type":"heading","depth":3,"position":{"start":{"line":779,"column":1},"end":{"line":779,"column":1}},"children":[{"type":"text","value":"Distribution Fitting and Testing","position":{"start":{"line":779,"column":1},"end":{"line":779,"column":1}},"key":"ssqXy1tKAp"}],"identifier":"distribution-fitting-and-testing","label":"Distribution Fitting and Testing","html_id":"distribution-fitting-and-testing","implicit":true,"key":"YlFDM88R7t"},{"type":"code","lang":"python","value":"def statistical_analysis():\n    \"\"\"Statistical tests for astronomical data.\"\"\"\n    \n    # Generate galaxy cluster data\n    np.random.seed(42)\n    \n    # Two clusters with different properties\n    n1, n2 = 150, 100\n    \n    # Cluster 1: nearby, rich\n    velocities1 = np.random.normal(5000, 800, n1)  # km/s\n    luminosities1 = np.random.lognormal(10, 0.5, n1)  # Solar luminosities\n    \n    # Cluster 2: distant, poor\n    velocities2 = np.random.normal(15000, 600, n2)\n    luminosities2 = np.random.lognormal(9.5, 0.7, n2)\n    \n    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n    \n    # 1. Histogram and distribution fitting\n    from scipy.stats import norm, lognorm\n    \n    # Velocity distribution\n    axes[0, 0].hist(velocities1, bins=20, alpha=0.5, density=True, label='Cluster 1')\n    axes[0, 0].hist(velocities2, bins=20, alpha=0.5, density=True, label='Cluster 2')\n    \n    # Fit normal distributions\n    mu1, std1 = norm.fit(velocities1)\n    mu2, std2 = norm.fit(velocities2)\n    \n    v_range = np.linspace(0, 20000, 100)\n    axes[0, 0].plot(v_range, norm.pdf(v_range, mu1, std1), 'b-', linewidth=2)\n    axes[0, 0].plot(v_range, norm.pdf(v_range, mu2, std2), 'r-', linewidth=2)\n    axes[0, 0].set_xlabel('Velocity [km/s]')\n    axes[0, 0].set_ylabel('Probability Density')\n    axes[0, 0].set_title('Velocity Distributions')\n    axes[0, 0].legend()\n    \n    # 2. Q-Q plot for normality test\n    from scipy.stats import probplot\n    \n    probplot(velocities1, dist=\"norm\", plot=axes[0, 1])\n    axes[0, 1].set_title('Q-Q Plot (Cluster 1 Velocities)')\n    \n    # 3. Two-sample tests\n    from scipy.stats import ks_2samp, mannwhitneyu, ttest_ind\n    \n    # Kolmogorov-Smirnov test\n    ks_stat, ks_pvalue = ks_2samp(velocities1, velocities2)\n    \n    # Mann-Whitney U test (non-parametric)\n    mw_stat, mw_pvalue = mannwhitneyu(velocities1, velocities2)\n    \n    # Student's t-test (parametric)\n    t_stat, t_pvalue = ttest_ind(velocities1, velocities2)\n    \n    axes[0, 2].text(0.1, 0.8, 'Two-Sample Tests:', fontsize=12, fontweight='bold',\n                   transform=axes[0, 2].transAxes)\n    axes[0, 2].text(0.1, 0.6, f'K-S test: p = {ks_pvalue:.3e}',\n                   transform=axes[0, 2].transAxes)\n    axes[0, 2].text(0.1, 0.5, f'Mann-Whitney: p = {mw_pvalue:.3e}',\n                   transform=axes[0, 2].transAxes)\n    axes[0, 2].text(0.1, 0.4, f't-test: p = {t_pvalue:.3e}',\n                   transform=axes[0, 2].transAxes)\n    axes[0, 2].text(0.1, 0.2, 'p < 0.05 suggests different distributions',\n                   transform=axes[0, 2].transAxes, fontsize=10, style='italic')\n    axes[0, 2].axis('off')\n    \n    # 4. Correlation analysis\n    from scipy.stats import spearmanr, pearsonr\n    \n    # Add some correlation\n    masses1 = luminosities1 + np.random.normal(0, 1, n1)\n    masses2 = luminosities2 + np.random.normal(0, 1, n2)\n    \n    # Combine data\n    all_lum = np.concatenate([luminosities1, luminosities2])\n    all_mass = np.concatenate([masses1, masses2])\n    \n    axes[1, 0].scatter(np.log10(luminosities1), np.log10(masses1), \n                      alpha=0.5, label='Cluster 1')\n    axes[1, 0].scatter(np.log10(luminosities2), np.log10(masses2), \n                      alpha=0.5, label='Cluster 2')\n    axes[1, 0].set_xlabel('log(Luminosity) [L☉]')\n    axes[1, 0].set_ylabel('log(Mass) [M☉]')\n    axes[1, 0].set_title('Mass-Luminosity Relation')\n    axes[1, 0].legend()\n    \n    # Calculate correlations\n    pearson_r, pearson_p = pearsonr(np.log10(all_lum), np.log10(all_mass))\n    spearman_r, spearman_p = spearmanr(all_lum, all_mass)\n    \n    axes[1, 0].text(0.05, 0.95, f'Pearson r = {pearson_r:.3f}',\n                   transform=axes[1, 0].transAxes)\n    axes[1, 0].text(0.05, 0.90, f'Spearman ρ = {spearman_r:.3f}',\n                   transform=axes[1, 0].transAxes)\n    \n    # 5. Bootstrap confidence intervals\n    from scipy.stats import bootstrap\n    \n    def median_diff(x, y):\n        \"\"\"Difference in medians.\"\"\"\n        return np.median(x) - np.median(y)\n    \n    # Bootstrap\n    rng = np.random.default_rng(42)\n    res = bootstrap((velocities1, velocities2), \n                   lambda x, y: np.median(x) - np.median(y),\n                   n_resamples=10000,\n                   confidence_level=0.95,\n                   random_state=rng,\n                   method='percentile')\n    \n    axes[1, 1].hist(res.bootstrap_distribution, bins=50, alpha=0.7)\n    axes[1, 1].axvline(res.confidence_interval.low, color='red', \n                      linestyle='--', label='95% CI')\n    axes[1, 1].axvline(res.confidence_interval.high, color='red', \n                      linestyle='--')\n    axes[1, 1].set_xlabel('Median Velocity Difference [km/s]')\n    axes[1, 1].set_ylabel('Count')\n    axes[1, 1].set_title('Bootstrap Distribution')\n    axes[1, 1].legend()\n    \n    # 6. Survival analysis (for truncated data)\n    from scipy.stats import kaplan_meier_estimator\n    \n    # Simulate detection limits\n    detection_limit = 11.0\n    detected1 = luminosities1 > detection_limit\n    detected2 = luminosities2 > detection_limit\n    \n    # This is simplified - real survival analysis needs more care\n    axes[1, 2].hist(luminosities1[detected1], bins=20, alpha=0.5, \n                   label=f'Cluster 1 ({detected1.sum()}/{n1} detected)')\n    axes[1, 2].hist(luminosities2[detected2], bins=20, alpha=0.5,\n                   label=f'Cluster 2 ({detected2.sum()}/{n2} detected)')\n    axes[1, 2].axvline(detection_limit, color='red', linestyle='--', \n                      label='Detection limit')\n    axes[1, 2].set_xlabel('Luminosity [L☉]')\n    axes[1, 2].set_ylabel('Count')\n    axes[1, 2].set_title('Truncated Data')\n    axes[1, 2].legend()\n    \n    plt.tight_layout()\n    plt.show()\n\nstatistical_analysis()","position":{"start":{"line":781,"column":1},"end":{"line":929,"column":1}},"key":"kUzUVQfmBa"},{"type":"heading","depth":2,"position":{"start":{"line":931,"column":1},"end":{"line":931,"column":1}},"children":[{"type":"text","value":"Try It Yourself","position":{"start":{"line":931,"column":1},"end":{"line":931,"column":1}},"key":"frUpNv4nEV"}],"identifier":"try-it-yourself","label":"Try It Yourself","html_id":"try-it-yourself","implicit":true,"key":"B9OigR9GZ2"},{"type":"heading","depth":3,"position":{"start":{"line":933,"column":1},"end":{"line":933,"column":1}},"children":[{"type":"text","value":"Exercise 1: Build a Complete Spectral Analysis Pipeline","position":{"start":{"line":933,"column":1},"end":{"line":933,"column":1}},"key":"hQZXsHrkrP"}],"identifier":"exercise-1-build-a-complete-spectral-analysis-pipeline","label":"Exercise 1: Build a Complete Spectral Analysis Pipeline","html_id":"exercise-1-build-a-complete-spectral-analysis-pipeline","implicit":true,"key":"bUcbtl7rcV"},{"type":"code","lang":"python","value":"def spectral_analysis_pipeline(wavelength, flux, error):\n    \"\"\"\n    Complete spectral analysis pipeline.\n    \n    Tasks:\n    1. Interpolate to common wavelength grid\n    2. Identify and mask cosmic rays\n    3. Fit and subtract continuum\n    4. Find emission/absorption lines\n    5. Measure line properties (EW, FWHM, flux)\n    6. Estimate radial velocity\n    7. Calculate S/N ratio\n    \"\"\"\n    # Your code here\n    pass","position":{"start":{"line":935,"column":1},"end":{"line":951,"column":1}},"key":"LxMUoLRmsZ"},{"type":"heading","depth":3,"position":{"start":{"line":953,"column":1},"end":{"line":953,"column":1}},"children":[{"type":"text","value":"Exercise 2: Orbital Fitting with MCMC","position":{"start":{"line":953,"column":1},"end":{"line":953,"column":1}},"key":"tCKQ7jTPkO"}],"identifier":"exercise-2-orbital-fitting-with-mcmc","label":"Exercise 2: Orbital Fitting with MCMC","html_id":"exercise-2-orbital-fitting-with-mcmc","implicit":true,"key":"mFqGGXOU7A"},{"type":"code","lang":"python","value":"def fit_exoplanet_orbit(times, radial_velocities, errors):\n    \"\"\"\n    Fit Keplerian orbit to radial velocity data.\n    \n    Parameters to fit:\n    - Period\n    - Eccentricity\n    - Semi-amplitude\n    - Argument of periastron\n    - Time of periastron\n    - Systemic velocity\n    \n    Use MCMC for proper uncertainty estimation.\n    \"\"\"\n    # Your code here\n    pass","position":{"start":{"line":955,"column":1},"end":{"line":972,"column":1}},"key":"LTPgboXpxA"},{"type":"heading","depth":3,"position":{"start":{"line":974,"column":1},"end":{"line":974,"column":1}},"children":[{"type":"text","value":"Exercise 3: Image Deconvolution","position":{"start":{"line":974,"column":1},"end":{"line":974,"column":1}},"key":"mHI0a9xemX"}],"identifier":"exercise-3-image-deconvolution","label":"Exercise 3: Image Deconvolution","html_id":"exercise-3-image-deconvolution","implicit":true,"key":"R7EAPYvfZg"},{"type":"code","lang":"python","value":"def deconvolve_image(image, psf, method='richardson-lucy'):\n    \"\"\"\n    Deconvolve astronomical image.\n    \n    Methods:\n    - Richardson-Lucy\n    - Wiener filter\n    - Blind deconvolution\n    \n    Handle noise and artifacts properly.\n    \"\"\"\n    # Your code here\n    pass","position":{"start":{"line":976,"column":1},"end":{"line":990,"column":1}},"key":"al6mejmeV6"},{"type":"heading","depth":2,"position":{"start":{"line":992,"column":1},"end":{"line":992,"column":1}},"children":[{"type":"text","value":"Key Takeaways","position":{"start":{"line":992,"column":1},"end":{"line":992,"column":1}},"key":"VANtNe3dbK"}],"identifier":"key-takeaways","label":"Key Takeaways","html_id":"key-takeaways","implicit":true,"key":"cXPQQPhH6z"},{"type":"paragraph","position":{"start":{"line":994,"column":1},"end":{"line":1001,"column":1}},"children":[{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"cocjBeglVS"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"SciPy provides optimized algorithms","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"zZtV25esAS"}],"key":"xGdhQaJ5yn"},{"type":"text","value":" - Don’t reinvent the wheel","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"U2gcryEi89"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"jxJwSSNDNt"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"vcIhFOS6KS"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Choose interpolation carefully","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"L3zWReyS8A"}],"key":"VFCWnYQiWP"},{"type":"text","value":" - Cubic can oscillate, consider Akima","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"risAZTR0bo"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"kSWqMqASqR"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"lGaMfHiRiP"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Never blindly extrapolate","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"rtsnUagYii"}],"key":"spG6CUOahp"},{"type":"text","value":" - Use physical models instead","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"NbAuk0gEvO"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"A1372PYcuN"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"BothbPOrj5"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Integration has many methods","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"E9kWjj8q4H"}],"key":"sBQfETaUL6"},{"type":"text","value":" - Adaptive quadrature, Monte Carlo for high-D","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"wYfKv8vUJr"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"kbzdKfQMqM"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"LuB7oMucRa"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"ODEs need appropriate solvers","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"rpI3m0oKbN"}],"key":"cnAg9btfdj"},{"type":"text","value":" - RK45 for general, DOP853 for long integration","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"RJlfotCmtX"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"O04gSG9Klg"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"McDUpusJY3"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Optimization requires good initial guesses","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"DCQaxLx9hp"}],"key":"aWIm09MhRy"},{"type":"text","value":" - Consider global methods","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"SPDCDUGlE7"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"guNsOjoNbz"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"kiCvZclLK4"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Signal processing handles real data","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"fw9XoRLSjP"}],"key":"SzpLHQDsZf"},{"type":"text","value":" - Uneven sampling, noise, trends","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"Sescr9PaiN"},{"type":"break","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"afkGQeMcKM"},{"type":"text","value":"✅ ","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"gwfwRUfxaR"},{"type":"strong","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"children":[{"type":"text","value":"Statistical tests have assumptions","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"WGRDKwds6p"}],"key":"VxZ8ahqQqU"},{"type":"text","value":" - Check them before applying","position":{"start":{"line":994,"column":1},"end":{"line":994,"column":1}},"key":"ceGVPm6h5Q"}],"key":"CE6HivTM0J"},{"type":"heading","depth":2,"position":{"start":{"line":1003,"column":1},"end":{"line":1003,"column":1}},"children":[{"type":"text","value":"Next Steps","position":{"start":{"line":1003,"column":1},"end":{"line":1003,"column":1}},"key":"GtQR2tHLqw"}],"identifier":"next-steps","label":"Next Steps","html_id":"next-steps","implicit":true,"key":"VnbmJ14kgH"},{"type":"paragraph","position":{"start":{"line":1005,"column":1},"end":{"line":1005,"column":1}},"children":[{"type":"text","value":"You now have the foundation for scientific computing in Python:","position":{"start":{"line":1005,"column":1},"end":{"line":1005,"column":1}},"key":"ScwB5j1uwi"}],"key":"vk0qThAuPv"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":1006,"column":1},"end":{"line":1009,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":1006,"column":1},"end":{"line":1006,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1006,"column":1},"end":{"line":1006,"column":1}},"children":[{"type":"text","value":"NumPy","position":{"start":{"line":1006,"column":1},"end":{"line":1006,"column":1}},"key":"IuqSQBJDWR"}],"key":"K2lnGe5Rmu"},{"type":"text","value":" for array operations and linear algebra","position":{"start":{"line":1006,"column":1},"end":{"line":1006,"column":1}},"key":"lQnJicpPz6"}],"key":"vGtBp7cP02"},{"type":"listItem","spread":true,"position":{"start":{"line":1007,"column":1},"end":{"line":1007,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1007,"column":1},"end":{"line":1007,"column":1}},"children":[{"type":"text","value":"Matplotlib","position":{"start":{"line":1007,"column":1},"end":{"line":1007,"column":1}},"key":"FMrsW9tYSr"}],"key":"h45ulVXeHO"},{"type":"text","value":" for publication-quality visualizations","position":{"start":{"line":1007,"column":1},"end":{"line":1007,"column":1}},"key":"Jr46yD8Als"}],"key":"AvRFjImYuq"},{"type":"listItem","spread":true,"position":{"start":{"line":1008,"column":1},"end":{"line":1009,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1008,"column":1},"end":{"line":1008,"column":1}},"children":[{"type":"text","value":"SciPy","position":{"start":{"line":1008,"column":1},"end":{"line":1008,"column":1}},"key":"YXizf2oTfH"}],"key":"CFngvoCaHz"},{"type":"text","value":" for numerical algorithms and analysis","position":{"start":{"line":1008,"column":1},"end":{"line":1008,"column":1}},"key":"nyHxn095fp"}],"key":"j3QysCnePk"}],"key":"XxtLFAFfwz"},{"type":"paragraph","position":{"start":{"line":1010,"column":1},"end":{"line":1010,"column":1}},"children":[{"type":"text","value":"Combined with your Python fundamentals and optimization techniques, you’re ready to tackle complex astronomical problems. The next section on Pandas will add powerful data manipulation capabilities for working with catalogs and time series data.","position":{"start":{"line":1010,"column":1},"end":{"line":1010,"column":1}},"key":"EHsWD3B2m7"}],"key":"kR039NMNW4"},{"type":"paragraph","position":{"start":{"line":1012,"column":1},"end":{"line":1012,"column":1}},"children":[{"type":"text","value":"Remember: These libraries work best together. Use NumPy for computation, SciPy for algorithms, and Matplotlib for visualization - all integrated in your astronomical workflows.","position":{"start":{"line":1012,"column":1},"end":{"line":1012,"column":1}},"key":"zsfrhxA41g"}],"key":"IJmolDqEPB"}],"key":"AXxPnnBJ7x"}],"key":"S1d3EycJBW"},"references":{"cite":{"order":[],"data":{}}}}