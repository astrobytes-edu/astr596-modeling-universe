{"version":2,"kind":"Article","sha256":"ccef246e7abad96b02e4528a4e4d4c590c1ca0b1457e58ff72ebb2ee36f4faef","slug":"course-overview-final","location":"/01-course-info/05-course-overview-final.md","dependencies":[],"frontmatter":{"title":"Understanding Your Learning Journey in ASTR 596","content_includes_title":false,"authors":[{"nameParsed":{"literal":"Anna Rosen","given":"Anna","family":"Rosen"},"name":"Anna Rosen","orcid":"0000-0003-4423-0660","email":"alrosen@sdsu.edu","affiliations":["San Diego State University"],"id":"contributors-myst-generated-uid-0","corresponding":true}],"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"MIT","url":"https://opensource.org/licenses/MIT","name":"MIT License","free":true,"osi":true}},"github":"https://github.com/astrobytes-edu/astr596-modeling-universe","subject":"Modeling the Universe","venue":{"title":"ASTR 596 - Fall 2025","url":"https://www.anna-rosen.com"},"keywords":["computational astrophysics","python","numerical methods","machine learning","monte carlo","neural networks","radiative transfer","bayesian inference","JAX"],"affiliations":[{"id":"San Diego State University","name":"San Diego State University"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/astrobytes-edu/astr596-modeling-universe/blob/main/01-course-info/05-course-overview-final.md","exports":[{"format":"md","filename":"05-course-overview-final.md","url":"/05-course-overview-f-605a72721c32c107ed38a9f7da42052f.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Why This Course is Designed the Way It Is","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"hTVZnSmpth"}],"identifier":"why-this-course-is-designed-the-way-it-is","label":"Why This Course is Designed the Way It Is","html_id":"why-this-course-is-designed-the-way-it-is","implicit":true,"key":"BvGa83nGv4"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This course follows a specific progression: ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Qv6hqS2o9f"},{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Fundamentals → Classical Methods → Statistical Methods → Modern ML","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hsG5KVV1ho"}],"key":"nZVf6EEOh5"},{"type":"text","value":". This mirrors how the field itself evolved, but more importantly, each topic builds essential skills for the next. You’ll essentially recreate the historical development of computational astrophysics, but in a compressed, logical sequence that maximizes your learning.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"QMfhtE0X3B"}],"key":"XrRbWXMWXu"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"At the heart of this course is the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"vSXheUQkRK"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"“glass box” philosophy","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"rRxLdIDrhn"}],"key":"JWDaHBHtf9"},{"type":"text","value":" — you’ll build every algorithm from scratch before using advanced libraries. This isn’t masochism; it’s pedagogy. When you implement backpropagation by hand, you understand why neural networks fail. When you code your own MCMC sampler, you recognize convergence problems. This deep understanding distinguishes computational scientists from software users. You’re learning to think, not just code.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"POkedIpAHU"}],"key":"EPvwI7R2yG"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Understanding the “why” behind your curriculum helps you see the forest through the trees and appreciate how each assignment builds toward your growth as a computational scientist. Throughout this journey, you’ll also develop AI literacy — starting with minimal assistance while building foundations, then progressively integrating AI tools as a research amplifier once you understand what’s happening under the hood.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"ZwncadnAbB"}],"key":"mtKGxXkOEf"},{"type":"heading","depth":2,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"What This Course Isn’t","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"pGvJ3vZ6JV"}],"identifier":"what-this-course-isnt","label":"What This Course Isn’t","html_id":"what-this-course-isnt","implicit":true,"key":"SB850Gm3FN"},{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"This isn’t a survey of astronomical software packages where you learn to use astropy or MESA. You won’t be calling pre-built functions or following tutorials. Every algorithm you implement will solve real astrophysical problems. You’ll build your own versions of professional tools, understanding their strengths and limitations through direct experience.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pZb5uAV6uo"}],"key":"FyNECjaVSm"},{"type":"heading","depth":2,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"The Four-Phase Journey","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Elj439XrNY"}],"identifier":"the-four-phase-journey","label":"The Four-Phase Journey","html_id":"the-four-phase-journey","implicit":true,"key":"Wck1TdjfDg"},{"type":"heading","depth":3,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Phase 1: Foundation Building","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"EABZ93vGrN"}],"identifier":"phase-1-foundation-building","label":"Phase 1: Foundation Building","html_id":"phase-1-foundation-building","implicit":true,"key":"LNji1R0V0V"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"You start with stellar physics because it’s conceptually accessible — everyone intuitively understands that hot things glow and massive things attract. Implementing a ","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"JWdpjagZl3"},{"type":"inlineCode","value":"Star","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"Dp7tqzZhiQ"},{"type":"text","value":" class teaches object-oriented thinking naturally. A star has properties (mass, temperature, luminosity) and methods (evolve, radiate, calculate_lifetime). This makes OOP concrete rather than abstract.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"oGkeIDkZRi"}],"key":"tnyVBlY2vk"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"You’ll then build a ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"e8LbYC8Bvs"},{"type":"inlineCode","value":"StellarPopulation","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"mOMopW39hv"},{"type":"text","value":" class that manages hundreds to thousands of stars simultaneously. Here’s where you’ll discover the power of vectorization — a fundamental concept in scientific computing. Instead of writing loops like:","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"ivdo9ifjEk"}],"key":"ZhTxehOrTm"},{"type":"code","lang":"python","value":"for star in stars:\n    star.luminosity = calculate_luminosity(star.mass)","position":{"start":{"line":22,"column":1},"end":{"line":25,"column":1}},"key":"N5VQOjJ1kb"},{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"You’ll learn to think in arrays:","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"A23z7GGTis"}],"key":"pWOXXKohC9"},{"type":"code","lang":"python","value":"luminosities = stellar_constant * masses**3.5  # Main sequence relation, all stars at once!","position":{"start":{"line":27,"column":1},"end":{"line":29,"column":1}},"key":"jsKBJA3Cuj"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"This single line replaces thousands of function calls. Your code will run ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"x9PylZ6v5b"},{"type":"emphasis","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"much","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"yQYVMZhU5r"}],"key":"puE4gWYxvK"},{"type":"text","value":" faster using NumPy’s vectorized operations. This isn’t just about speed—vectorized thinking changes how you approach problems. Instead of “for each particle, calculate force,” you’ll think “calculate all forces simultaneously as matrix operations.” This mental shift is essential for everything that follows: Monte Carlo simulations, neural network operations, and JAX’s array programming paradigm all require this vectorized mindset.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"hY9ltQNRUN"}],"key":"mEdpEzRMtH"},{"type":"paragraph","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"N-body dynamics becomes your introduction to numerical methods. The physics is simple (","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"gbtqBWuWXD"},{"type":"inlineMath","value":"F = GM m/r^2","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mo>=</mo><mi>G</mi><mi>M</mi><mi>m</mi><mi mathvariant=\"normal\">/</mi><msup><mi>r</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">F = GM m/r^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">GM</span><span class=\"mord mathnormal\">m</span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span>","key":"sMLTq2HQkE"},{"type":"text","value":") but you can’t solve it analytically for ","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"LlP7MAGihW"},{"type":"inlineMath","value":"N>2","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>&gt;</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">N&gt;2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7224em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2</span></span></span></span>","key":"Pc0923rVhi"},{"type":"text","value":". You’ll discover firsthand why algorithm choices matter when your solar system flies apart using Euler integration but remains stable with Verlet.","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"Joe4ugalj1"}],"key":"AIkKabhKnz"},{"type":"heading","depth":3,"position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Phase 2: Bridge to Statistical Thinking (Weeks 4-6)","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"nHeUhkbUkV"}],"identifier":"phase-2-bridge-to-statistical-thinking-weeks-4-6","label":"Phase 2: Bridge to Statistical Thinking (Weeks 4-6)","html_id":"phase-2-bridge-to-statistical-thinking-weeks-4-6","implicit":true,"key":"I67NDsAtQ3"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"After mastering deterministic physics, you’re ready for the probabilistic world. Monte Carlo serves as the perfect bridge between these paradigms. Monte Carlo methods use random sampling to solve problems that would be intractable otherwise — imagine trying to calculate ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"RTN6O6Gd7s"},{"type":"inlineMath","value":"\\pi","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span>","key":"w3tPSjEZkA"},{"type":"text","value":" by randomly throwing darts at a circle inscribed in a square, or computing complex integrals by randomly sampling the function. You’re still solving physics problems, but now through statistical approximation rather than exact calculation. This prepares your mind for the probabilistic thinking required in machine learning, where uncertainty and randomness are features, not bugs.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"TPPNi1dmiF"}],"key":"u2LstkhjwT"},{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Linear regression introduces core ML concepts. Starting from scratch means deriving the normal equation ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"EAUyBmjwgx"},{"type":"inlineMath","value":"(X^TX)\\beta = X^Ty","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msup><mi>X</mi><mi>T</mi></msup><mi>X</mi><mo stretchy=\"false\">)</mo><mi>β</mi><mo>=</mo><msup><mi>X</mi><mi>T</mi></msup><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">(X^TX)\\beta = X^Ty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0913em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0358em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">X</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span>","key":"rAfJMbw8u5"},{"type":"text","value":", which shows you that ML isn’t magic — it’s using math and code to recognize patterns in your data. You’ll understand optimization, gradient descent, and regularization by building them yourself. You’ll discover how adding a simple penalty term (regularization) prevents your model from memorizing noise, a concept that extends all the way to modern neural networks.","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"B9TFymqWrb"}],"key":"nmb8R8NZRH"},{"type":"paragraph","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"strong","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"Your “aha!” moment","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"joOOelTXCH"}],"key":"S1Qb1wQKjc"},{"type":"text","value":": When you see the Central Limit Theorem emerge naturally from your Monte Carlo simulations — no matter what distribution you sample from, the mean converges to a Gaussian. This isn’t just theory; you’ll watch it happen in real-time through your own code.","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"aP8vQvrn2C"}],"key":"XV2la6nB2h"},{"type":"paragraph","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"text","value":"Each project now requires extensions where you ask “what if?” — what if we vary the initial mass distribution to the N-body code? What if we use different sampling strategies? This “I want you to think” approach mirrors real research where the interesting discoveries come from exploring beyond the minimum requirements.","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"FvYFiCmDTH"}],"key":"QGyfrOmSja"},{"type":"heading","depth":3,"position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Phase 3: Advanced Statistical Methods","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"VkvjhIuJNx"}],"identifier":"phase-3-advanced-statistical-methods","label":"Phase 3: Advanced Statistical Methods","html_id":"phase-3-advanced-statistical-methods","implicit":true,"key":"NOFrIG9uOq"},{"type":"paragraph","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"strong","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Radiative Transfer","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"NBgjgbtiSD"}],"key":"qXth8DBG7o"},{"type":"text","value":" (RT) is arguably the most important topic in modern astrophysics, both observationally and theoretically, since it is how we understand everything we see in the universe. You’ll implement ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"ooLXTUffmJ"},{"type":"strong","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"Monte Carlo Radiative Transfer","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"nYE1M6G6i5"}],"key":"gJI6YmzPMU"},{"type":"text","value":" (MCRT) from scratch, simulating individual photon packets as they scatter, absorb, and re-emit through dusty media. By tracking a large sample of random photon paths, you’ll predict what telescopes observe when looking through cosmic dust. You’ll connect this to your N-body project by modeling dust extinction along different sight lines through your simulated star clusters.","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"mGAyDzPBBw"}],"key":"fv2mrezq2z"},{"type":"paragraph","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Bayesian Inference and MCMC","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"a4TlH2mU2s"}],"key":"oWpD8lqkCo"},{"type":"text","value":" represents the intellectual peak of the course. Bayesian inference flips traditional statistics: instead of asking ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"yRtSYz8JOk"},{"type":"emphasis","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"“what’s the probability of this data given my model?”","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"f9cBQiJCmF"}],"key":"UJCdqydY53"},{"type":"text","value":" you ask ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"LKjMdKZqAI"},{"type":"emphasis","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"“what’s the probability of my model given this data?”","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"od6XJou3ur"}],"key":"MjK2LvyGpg"},{"type":"text","value":" This is formalized in ","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"ijDzH9AZWB"},{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Bayes’ theorem","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"X8vHXxGjh4"}],"key":"WHVtvgBziB"},{"type":"text","value":":","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"WiLcCyGZqd"}],"key":"MjplCEIjqO"},{"type":"paragraph","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"inlineMath","value":"P(\\theta|D) = \\frac{P(D|\\theta) \\cdot P(\\theta)}{P(D)}","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi>D</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>D</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>D</mi><mo stretchy=\"false\">)</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(\\theta|D) = \\frac{P(D|\\theta) \\cdot P(\\theta)}{P(D)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.53em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose mtight\">)</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord mtight\">∣</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">⋅</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>","key":"ojFjO7fkDD"}],"key":"tcq6rV5A7X"},{"type":"paragraph","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"where ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"n1tIGY0QEE"},{"type":"inlineMath","value":"P(\\theta|D)","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi>D</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(\\theta|D)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span></span></span></span>","key":"NBVPZbw1nt"},{"type":"text","value":" is the posterior (","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"dY2Omifpiv"},{"type":"emphasis","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"what we want","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"AZueIrUXjg"}],"key":"t9oE9Ts58R"},{"type":"text","value":" — probability of parameters given data), ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"RdaQi6knmt"},{"type":"inlineMath","value":"P(D|\\theta)","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>D</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(D|\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord\">∣</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>","key":"MiA0rOJ670"},{"type":"text","value":" is the likelihood (probability of observing this data if our model is true), ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"cUTBnrCs2m"},{"type":"inlineMath","value":"P(\\theta)","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>","key":"Tl7pczSGvB"},{"type":"text","value":" is the prior (our beliefs before seeing the data), and ","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"A2a38UH7uo"},{"type":"inlineMath","value":"P(D)","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>D</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">P(D)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span></span></span></span>","key":"qYwjPi5oVh"},{"type":"text","value":" is the evidence ( normalization constant).","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"butzf2Llre"}],"key":"zNXBAsgXHn"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"The revolutionary insight is the prior — you can mathematically encode what you believe is reasonable before seeing any data. These beliefs might be wrong! Often that’s fine since strong data will override weak priors. But when data is sparse (like it always is in astronomy), priors help constrain solutions to physically plausible regions. MCMC (Markov Chain Monte Carlo) is how you explore these probability distributions. Imagine a random walker that spends more time in high-probability regions, eventually mapping out the entire parameter landscape.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"g4RJRhlfDP"}],"key":"tA4BvoxI5f"},{"type":"heading","depth":3,"position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"Phase 4: Modern Machine Learning (Weeks 11-16)","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"Yj07NmYfBm"}],"identifier":"phase-4-modern-machine-learning-weeks-11-16","label":"Phase 4: Modern Machine Learning (Weeks 11-16)","html_id":"phase-4-modern-machine-learning-weeks-11-16","implicit":true,"key":"IadSqmq9HK"},{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"With strong statistical foundations, you’re ready for the frontier. ","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"x5Vpa4na2x"},{"type":"strong","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"Gaussian Processes","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"YIsmgN2xMp"}],"key":"gnJpnGSWzl"},{"type":"text","value":" (GPs) bridge classical statistics and modern ML. They’re still Bayesian but now you’re ","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"a1vKwWdBmG"},{"type":"emphasis","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"learning","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"rxT921e56f"}],"key":"W2R7AOw0m6"},{"type":"text","value":" functions, not parameters. Think of GPs as a probability distribution over functions. Instead of fitting a specific curve to your data, you’re modeling all possible curves that could explain it, weighted by their probability. This lets you quantify uncertainty everywhere: you’ll know not just the predicted value but also how confident you should be in that prediction. GPs are non-parametric models meaning that they grow in complexity with your data rather than having a fixed number of parameters.","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"owBICpVMrI"}],"key":"mJ3jD1jpUK"},{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"The culmination of the course is your final project: building a neural network from scratch using ","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"fDnKKO0vNl"},{"type":"inlineCode","value":"JAX","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"iriFe1aIJJ"},{"type":"text","value":". First, you’ll implement every component manually — forward propagation (passing data through layers of artificial neurons), backpropagation (computing gradients via the chain rule), and gradient descent (updating weights to minimize loss). You’ll build the same fundamental algorithms powering ChatGPT and DALL-E, just at a much smaller scale. This removes the black box mystique. Neural networks are just clever applications of calculus and linear algebra you already understand.","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"gifgq6ZYbg"}],"key":"yWPdrdhnyh"},{"type":"paragraph","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"strong","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"Why ","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"akp3q4k1Pj"},{"type":"inlineCode","value":"JAX","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"iTuS4kYVXo"},{"type":"text","value":"?","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"wg7R0Rh7Vc"}],"key":"lJkdYTuikm"},{"type":"text","value":" Developed by Google, it’s the framework of choice for cutting-edge numerical computing and ML research in industry and is gaining attention in academic research. ","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"m3DCKXqe0I"},{"type":"inlineCode","value":"JAX","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"kKHvSjFdCv"},{"type":"text","value":" transforms scientific computing through automatic differentiation (autodiff) — it can automatically compute gradients of any function you write, no matter how complex. Remember struggling with derivatives in your orbital dynamics code? JAX handles that automatically. Those painful gradient calculations for linear regression? JAX makes them trivial. This isn’t just convenience; autodiff makes previously intractable problems solvable. You can optimize any differentiable system. Learning ","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"Im2rSu89gn"},{"type":"inlineCode","value":"JAX","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"jKvyRM4Dlr"},{"type":"text","value":" makes you industry-ready while keeping you at the research frontier.","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"b2Kbdem2ES"}],"key":"JP1gsFFKin"},{"type":"paragraph","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"You’ll take one of your previous projects and extend it with neural networks to answer a new scientific question. Your simulations generate training data, neural networks learn the patterns, and suddenly you can predict outcomes without running expensive simulations.","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"KYodjq3wHA"}],"key":"BLQ4J1QZMF"},{"type":"paragraph","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"strong","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Your final “aha!” moment","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"O8vmXXUTZW"}],"key":"Gn3UDX1eFr"},{"type":"text","value":": When your neural network learns patterns you didn’t explicitly program—perhaps discovering a relationship in stellar evolution you hadn’t noticed, or finding an optimal sampling strategy for your MCRT code. You’ll realize you’ve built something that can discover things you don’t know.","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"AqBLc1fGTV"}],"key":"yD1Hvo2asz"},{"type":"paragraph","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"By Phase 4, that initial feeling of “this is actually fun” has evolved into genuine research capability. You’re ready to implement any algorithm from a paper, combine classical and modern methods creatively, and contribute to the field.","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"I1Ln9FHdQZ"}],"key":"GmBt89V13L"},{"type":"heading","depth":2,"position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"text","value":"Why This Progression Works","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"gFhrhrM6Pa"}],"identifier":"why-this-progression-works","label":"Why This Progression Works","html_id":"why-this-progression-works","implicit":true,"key":"J5Lck0EH6Z"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":72,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":72,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"children":[{"type":"strong","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"children":[{"type":"text","value":"Each topic motivates the next","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"U8ePOLtttc"}],"key":"BTMjAEyMMa"},{"type":"text","value":": Numerical integration struggles motivate Monte Carlo. Monte Carlo motivates statistics. Statistics motivates ML. Your frustrations become the seeds of insight.","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"AohreqAFOf"}],"key":"GFJnGPg4Vt"}],"key":"TXbMugnYPm"},{"type":"listItem","spread":true,"position":{"start":{"line":74,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"strong","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"Complexity ramps gradually","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"cfWuH6CZZi"}],"key":"AOpPXmdgES"},{"type":"text","value":": Start with ","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"ElP8xeGKMM"},{"type":"inlineMath","value":"F=ma","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mo>=</mo><mi>m</mi><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">F=ma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">ma</span></span></span></span>","key":"bh12SkO5XD"},{"type":"text","value":", end with neural networks, but each step is manageable. You’re never asked to take multiple conceptual leaps simultaneously.","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"Il8lN6IKTo"}],"key":"erUPKz1Tkk"}],"key":"VF353NYMUL"},{"type":"listItem","spread":true,"position":{"start":{"line":76,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"strong","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"Real astrophysics throughout","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"hs8jnoeePW"}],"key":"SVDokyLG5D"},{"type":"text","value":": Every algorithm solves actual astronomy problems. You’re not learning abstract methods — you’re building tools astronomers use daily.","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"F32C80V7As"}],"key":"HvbWGnIUtH"}],"key":"BkekhYUAu2"},{"type":"listItem","spread":true,"position":{"start":{"line":78,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"strong","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"text","value":"Modern skills emerge from fundamentals","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"y3BpyBayLC"}],"key":"WL8BuavSTE"},{"type":"text","value":": By the end, you understand what ","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"AukP9zBVPs"},{"type":"inlineCode","value":"JAX","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"pSrOtjpcdo"},{"type":"text","value":" and modern tools do under the hood because you’ve built their components yourself.","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"eV0MpyGptj"}],"key":"DjZQLUTpAh"}],"key":"DoPiDrIlBQ"}],"key":"TzjZ3tTWkX"},{"type":"heading","depth":2,"position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"What You’ll Gain","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"Fk28LyaH8y"}],"identifier":"what-youll-gain","label":"What You’ll Gain","html_id":"what-youll-gain","implicit":true,"key":"jDtDRp7BN0"},{"type":"paragraph","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"By the end of this course:","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"gezAIKWX75"}],"key":"WVkmAgLCbM"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":84,"column":1},"end":{"line":93,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":84,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"You’ll have built a portfolio of working astronomical software that solves real problems.","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"HcJ9FFhTio"}],"key":"aSqRhXoLi2"}],"key":"klV5ZXKGsf"},{"type":"listItem","spread":true,"position":{"start":{"line":86,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"text","value":"You’ll understand methods from classical mechanics to neural networks — not just how to use them, but why they work.","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"Hu3dWwy0Ax"}],"key":"t2J2bvN33p"}],"key":"DThJaZ4PjN"},{"type":"listItem","spread":true,"position":{"start":{"line":88,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"You’ll be fluent in modern tools used at Google, DeepMind, and leading research institutions.","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"uG9UwM8A9L"}],"key":"wIIqCWDH7O"}],"key":"LB3466mZei"},{"type":"listItem","spread":true,"position":{"start":{"line":90,"column":1},"end":{"line":91,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"children":[{"type":"text","value":"You’ll be able to read research papers and implement new methods.","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"XFHdgNgnPj"}],"key":"IW8Pd4NhG1"}],"key":"N8lSiI9Hnm"},{"type":"listItem","spread":true,"position":{"start":{"line":92,"column":1},"end":{"line":93,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"text","value":"You’ll think computationally about physical problems while maintaining physical intuition about computational results.","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"BAmDuIxN4B"}],"key":"jttXUrH78X"}],"key":"HcGd3DB1tl"}],"key":"RYfnj4hATq"},{"type":"paragraph","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"This course teaches that computational astrophysics isn’t only about computers and astrophysics — it’s about thinking. How do we translate physical understanding into algorithms? How do we diagnose when those algorithms fail? How do we improve them? How do we know when to trust our results?","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"mZ28Vz7RCx"}],"key":"jcxlkzz0H2"},{"type":"paragraph","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"children":[{"type":"text","value":"The same mathematical structures appear everywhere: calculus and optimization, linear algebra, probability theory. A small set of fundamental ideas powers everything from stellar evolution to deep learning. This unity reveals the deep elegance underlying computational science.","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"hyBEWiDpCJ"}],"key":"NsMKKdOO7T"}],"key":"Q1qm6Zamhc"}],"key":"ivymn9AZhY"},"references":{"cite":{"order":[],"data":{}}}}